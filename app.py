import streamlit as st
import os
import io
from PIL import Image
import exifread
import numpy as np
# try:
#     import cv2  # Added debug print to confirm import
#     print("OpenCV imported successfully, version:", cv2.__version__)
# except ImportError as e:
#     st.error("Failed to import OpenCV: Ensure 'opencv-python' is in requirements.txt and redeploy. Error: " + str(e))
#     st.stop()
import pandas as pd
import folium
from streamlit_folium import st_folium
from ultralytics import YOLO
from tensorflow.keras.models import load_model
import torch
import logging
import gc

# Set page config as the FIRST Streamlit command
st.set_page_config(layout="wide", page_title="Road AI", page_icon="ğŸ›£ï¸")

# Debug to confirm Streamlit is running
print("Streamlit app initialized successfully")

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· logging
logging.basicConfig(filename="app.log", level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Allow Ultralytics DetectionModel in PyTorch safe globals
torch.serialization.add_safe_globals(['ultralytics.nn.tasks.DetectionModel'])

# Caching Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
@st.cache_resource
def load_yolo_model(model_path):
    return YOLO(model_path)

@st.cache_resource
def load_cnn_model(model_path):
    return load_model(model_path)

# Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
try:
    yolo_damages = load_yolo_model("yolov8s_rdd.pt")
    yolo_signs = load_yolo_model("yolov8s_gtsdb.pt")
    cnn_model = load_cnn_model("gtsrb_cnn_model.h5")
except Exception as e:
    st.error(f"Failed to load models: {e}")
    st.stop()

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï†Î±ÎºÎ­Î»Î¿Ï… Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
os.makedirs("outputs", exist_ok=True)

# Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î® GPS Î±Ï€ÏŒ EXIF
def extract_gps_from_image(file_like):
    file_like.seek(0)
    try:
        tags = exifread.process_file(file_like, details=False)
        lat_ref = tags["GPS GPSLatitudeRef"].values
        lon_ref = tags["GPS GPSLongitudeRef"].values
        lat = tags["GPS GPSLatitude"].values
        lon = tags["GPS GPSLongitude"].values

        def dms_to_dd(dms, ref):
            d = float(dms[0].num) / dms[0].den
            m = float(dms[1].num) / dms[1].den
            s = float(dms[2].num) / dms[2].den
            dd = d + m/60 + s/3600
            if ref in ['S', 'W']:
                dd = -dd
            return dd

        return dms_to_dd(lat, lat_ref), dms_to_dd(lon, lon_ref)
    except Exception as e:
        logging.warning(f"No GPS data: {e}")
        return None, None

# Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚
def process_image(uploaded_file, mode, yolo_damages, yolo_signs, cnn_model):
    result = {}
    try:
        file_bytes = uploaded_file.getvalue()
        image = Image.open(io.BytesIO(file_bytes)).convert("RGB")
        img_array = np.array(image)
        filename = uploaded_file.name
        lat, lon = extract_gps_from_image(io.BytesIO(file_bytes))

        MAX_FILE_SIZE = 10 * 1024 * 1024
        if len(file_bytes) > MAX_FILE_SIZE:
            raise ValueError(f"File {filename} exceeds 10MB limit")

        # Î‘Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î¼Îµ YOLO
        results = yolo_damages.predict(img_array, conf=0.25)[0] if mode == "Detect Damages" else yolo_signs.predict(img_array, conf=0.25)[0]
        logging.info(f"Processed {filename}: {len(results.boxes)} detections found, classes: {results.names}")

        if not results.boxes:
            logging.warning(f"No detections for {filename} in mode {mode}")
            st.warning(f"Î”ÎµÎ½ ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î± ÏƒÏ„Î·Î½ ÎµÎ¹ÎºÏŒÎ½Î±: {filename}")
            return None

        annotated_img = img_array.copy()
        for box in results.boxes:
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            label = results.names[cls]

            # cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            # cv2.putText(annotated_img, f"{label} {conf:.2f}", (x1, y1 - 10),
            #             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

            cnn_label = None
            if mode == "Detect Traffic Signs":
                try:
                    roi = img_array[y1:y2, x1:x2]
                    if roi.size == 0:
                        logging.warning(f"Empty ROI for {filename}")
                        continue
                    # roi_resized = cv2.resize(roi, (48, 48))  # Corrected to 48x48
                    # roi_normalized = roi_resized / 255.0
                    # roi_input = np.expand_dims(roi_normalized, axis=0)
                    # prediction = cnn_model.predict(roi_input, verbose=0)
                    # cnn_label = np.argmax(prediction, axis=1)[0]
                    logging.info(f"CNN prediction for {filename}: class {cnn_label}")
                except Exception as e:
                    logging.error(f"CNN failed for {filename}: {e}")
                    st.warning(f"Î— Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· CNN Î±Ï€Î­Ï„Ï…Ï‡Îµ Î³Î¹Î± Ï„Î·Î½ ÎµÎ¹ÎºÏŒÎ½Î± {filename}: {str(e)}")

            result = {
                "Filename": filename,
                "Type": "Damage" if mode == "Detect Damages" else "Sign",
                "Label": label,
                "CNN_Label": cnn_label,
                "Confidence": round(conf, 3),
                "Box": f"{x1},{y1},{x2},{y2}",
                "Latitude": lat,
                "Longitude": lon,
                "Annotated_Path": os.path.join("outputs", f"annotated_{filename}")
            }

        # Image.fromarray(annotated_img).save(result["Annotated_Path"])
        logging.info(f"Saved annotated image for {filename}")
    except Exception as e:
        logging.error(f"Error processing {uploaded_file.name}: {e}")
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï„Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ {filename}: {str(e)}")
        return None
    return result

# Streamlit UI
st.title("Road AI â€“ Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î¦Î¸Î¿ÏÏÎ½ & Î£Î·Î¼Î¬Ï„Ï‰Î½ Î¼Îµ GPS")

# Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î· Î¸ÎµÎ¼Î±Ï„Î¿Î»Î¿Î³Î¯Î±
st.markdown("""
    <style>
    .main {background-color: #f0f2f6;}
    .stButton>button {background-color: #4CAF50; color: white;}
    </style>
""", unsafe_allow_html=True)

# Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· session_state
if 'results_list' not in st.session_state:
    st.session_state.results_list = []
if 'df' not in st.session_state:
    st.session_state.df = None
if 'csv_file' not in st.session_state:
    st.session_state.csv_file = None
if 'annotated_images' not in st.session_state:
    st.session_state.annotated_images = []

# Î¦ÏŒÏÎ¼Î± Î³Î¹Î± ÎµÎ¯ÏƒÎ¿Î´Î¿
with st.form(key="analysis_form"):
    uploaded_files = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
    mode = st.selectbox("Î•Ï€Î¹Î»Î¿Î³Î® Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±Ï‚", ["Detect Damages", "Detect Traffic Signs"])
    run_button = st.form_submit_button("ğŸš€ Î•ÎºÎºÎ¯Î½Î·ÏƒÎ· Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚")

if run_button and uploaded_files:
    st.session_state.results_list = []
    st.session_state.df = None
    st.session_state.csv_file = None
    st.session_state.annotated_images = []

    progress_bar = st.progress(0)
    total_files = len(uploaded_files)
    for i, uploaded_file in enumerate(uploaded_files):
        result = process_image(uploaded_file, mode, yolo_damages, yolo_signs, cnn_model)
        if result:
            st.session_state.results_list.append(result)
        progress_bar.progress((i + 1) / total_files)
    st.success(f"âœ… Î•Ï€ÎµÎ¾ÎµÏÎ³Î¬ÏƒÏ„Î·ÎºÎ±Î½ {len(st.session_state.results_list)} ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼Î¿Î¯!")
    gc.collect()

# Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
if st.session_state.results_list:
    st.session_state.df = pd.DataFrame(st.session_state.results_list)
    
    st.subheader("ğŸ” Î¦Î¯Î»Ï„ÏÎ± Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½")
    confidence_threshold = st.slider("Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î· Î•Î¼Ï€Î¹ÏƒÏ„Î¿ÏƒÏÎ½Î·", 0.0, 1.0, 0.5)
    filtered_df = st.session_state.df[st.session
